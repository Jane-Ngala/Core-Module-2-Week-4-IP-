# Titanic Survivors / Spam Detection
<img src="https://user-images.githubusercontent.com/73166515/200243311-c7b1d9dc-999d-424e-8d18-dc24e7f3a559.png" width="950" height="550" />


This week's project requires us to implement a K-nearest neighbor (KNN) classifier  and a Naive Bayes classifier. Once we conduct the experiments, we will calculate the resulting metrics.

## Experimental Procedure:

### Download the two datasets from the given links:
Dataset 1 Source: [Link] 
Dataset 2 Source: [Link]

### Randomly partition each dataset into two parts i.e 80 - 20  sets.

### For dataset 1, because we don't have the label for the test set, we will use the train set to create train and test data (i.e. splitting further), then perform K-nearest neighbor classification.

### For dataset 2, perform classification of the testing set samples using the Naive Bayes Classifier.

### Compute the accuracy (percentage of correct classification).

### Report the confusion matrix of each classifier.

### Repeat step 2 to step 4 twice, each time splitting the datasets differently i.e. 70-30, 60-40, then note the outcomes of your modeling.

### Suggest and apply at least one optimization techniques.

### Provide further recommendations to improve both classifiers.
